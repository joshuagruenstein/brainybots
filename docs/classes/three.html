<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="../jemdoc.css" type="text/css" />
<script src="../index.js"></script>
<title>Markov Madness</title>
<!-- MathJax -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script>
<script src="https://cdn.jsdelivr.net/npm/roughjs@4.0.4/bundled/rough.min.js"></script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End MathJax -->
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Information</div>
<div class="menu-item"><a href="../index.html">Home</a></div>
<div class="menu-item"><a href="../docs.html">Robot&nbsp;Docs</a></div>
<div class="menu-item"><a href="https://github.com/joshuagruenstein/brainybots" target="blank">Github</a></div>
<div class="menu-category">Classes</div>
<div class="menu-item"><a href="../classes/one.html">Bayesian&nbsp;Bonanza</a></div>
<div class="menu-item"><a href="../classes/two.html">Decisions,&nbsp;Decisions</a></div>
<div class="menu-item"><a href="../classes/three.html" class="current">Markov&nbsp;Madness</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Markov Madness</h1>
</div>
<h3>Graphs</h3>
<p>First, we'll introduce the concept of graphs and then study how they can be applied to inference problems. We define a graph \(G = (V,E)\) as </p>
<ol>
<li><p>V- a set of vertices, also called nodes</p>
</li>
<li><p>E- a set of edges, which are pairs of vertices</p>
</li>
</ol>
<p>Note that edges can be directed or undirected- below we show an example of each. 
</p>
<p>Graphs are a natural way in which humans present information- for example, we might represent a system of highways and roads as a directed graph, which an edge going in the direction that traffic flows in. We're going to try to encode information and their dependencies using directed graphs. Let's consider again the event that you're eating ice cream on a given day. We might say that perhaps this event depends on the season and whether you're hungry. Whether you're hungry might depend on whether you've eaten dinner. A naive way that we might try to encode this is as follows 
</p>
<p>This brings us to the idea of graphical models. A graphical model is just a graph that in some way represents a set of distributions over random variables- each vertex represents a random variable (or event) and each edge in some way encodes a dependency. </p>
<p>First, let's look at what graphical models imply about the joint factorization. 

This graph represents the factorization of the joint as </p>
<p style="text-align:center">
\[
p_{x,y,z}(x,y,z) = p_x(x)p_{y|x}(y|x)p_{z|y}(z|y)
\]
</p><p>This makes some intuitive sense- the graph tells us that \(y\) really only depends on \(x\) and that \(z\) only really depends on \(y\), so a given event \(x,y,z\)'s likelihood can be computed using just those conditional dependencies, and the distribution of \(x\). This graph also yields another important result: we know that the joint can always be factored using the chain rule as </p>
<p style="text-align:center">
\[
p_{x,y,z}(x,y,z) = p_x(x)p_{y|x}(y|x)p_{z|y, x}(z|y, x)
\]
</p><p>So setting those two factorizations equal to each other, we have that </p>
<p style="text-align:center">
\[
p_{x,y,z}(x,y,z) = p_x(x)p_{y|x}(y|x)p_{z|y, x}(z|y, x) = p_x(x)p_{y|x}(y|x)p_{z|y}(z|y)
\]
</p><p>And simplifying, we find that \(p_{z|y, x}(z|y, x) = p_{z|y}(z|y)\). Note that this matches our definition of conditional independence somewhat- in that the two probabilities are the same conditioning on \(x\) and not conditioning on \(x\). In fact, this relationship says that \(z\) and \(x\) are conditionally independent given \(y\).</p>
<p>Let's look at another: 
</p>
<p>This case is called a common cause, because \(x\) and \(z\) both depend on this other variable, \(y\), so they share that common cause. So here, we do something similar with the factorization- we know that given \(y\), \(x\) and \(z\) only depend on \(y\), so our factorization of the joint is: </p>
<p style="text-align:center">
\[
p_{x,y,z}(x,y,z) = p_y(y)p_{x|y}(x|y)p_{z|y}(z|y)
\]
</p><p>Now, armed with the knowledge of these two types of graph structures, we'll look at a very cool model called the Hidden Markov Model. </p>
<p>blah blah blah
need lots of thoery first: graphs, HMMs (graphical models for factorization???) - teach directed graphical model for HMM s
By the end of this lecture, we should have and understand the following to implement the lab:</p>
<p style="text-align:center">
\[
P(X_{0.. T}|Y_{0..T}) \propto P(X_0, Y_0) \prod_{t=1}^T P(X_t | X_{t-1}) \prod_{t=1}^T P(Y_t | X_t)
\]
</p><p>Such that we can immediately after derive the forward algorithm with just the motivation from the gridmaze.</p>
<h2>Lab #3: time to explore!</h2>
<p>Last week, we used sensor readings from the robot to identify where we were in the maze.  As you may have noticed, this has some limitations: for example, consider the following robot positions:</p>
<canvas class="illustration" id="maze" style="height:400px"></canvas>
<p class="caption">Two robot positions with identical sensor readings.  How do we decide where we really are?</p>
<script>
make_maze("maze", [
    {pos:3, angle:0, color:'blue'},
    {pos:8, angle:0, color:'green'}
]);
</script>
<p>Even if the green and blue robots were to try every position of their sensor turret, they would still get the same exact readings.  Clearly, in order to determine where they are, the robots must <i>explore</i>!</p>
<p>To implement this, we will consider the robot localization problem as a hidden markov model.  Our hidden states \(X_{0..t}\) will be our robot positions, and \(Y_{0..t}\) will be our sensor readings.  At every timestep we'll take a random movement and then a sensor reading, and use this data to infer our robot position!</p>
<h3>The Forward Algorithm</h3>
<p>Derive forward algorithm from joint factorization, as motivated by this localization problem.  In class, we can do this in groups or all together.</p>
<h3>Moving the robot</h3>
<p>Up to this point, our robots have been stationary.  We can move our robots using some simple commands: <tt>bot.forward()</tt> to move one square forward, to move one square backward, <tt>bot.left()</tt> to turn 90 degrees to the left, and <tt>bot.right()</tt> to turn 90 degrees to the right.  </p>
<div class="infoblock">
<div class="blocktitle">Safety note</div>
<div class="blockcontent">
<p>After every call to <tt>bot.forward()</tt>, the robot will point its distance sensor forward and check if its safe to move before moving the sensor back to its previous position.  If there is a wall in front of the robot and the robot decides it's unsafe to move, <tt>bot.forward()</tt> will return <tt>False</tt>; otherwise, it will return <tt>True</tt>.  This is to ensure your robot does not run into walls. </p>
</div></div>
<p>Before you move on, test running a few movement commands in the Jupyter notebook.</p>
<h3>Inference building blocks</h3>
<p>Now it's time to begin building our inference pipeline.  For the equation for \(\alpha(x_t)\) in the forward algorithm, we will need \(P(X_0=x_0)\), \(P(X_{t}=x_t|X_{t-1}=x_{t-1}, U_{t}=u_{t})\), and \(P(Y_t=y_t | X_t=x_t)\).  Derive each of these expressions and implement them as Python methods in the Jupyter notebook.  Assume that the robot has equal chance of starting in any state.</p>
<div class="infoblock">
<div class="blocktitle">Implementation hint</div>
<div class="blockcontent">
<p>The method <tt>s_new = gm.simulatedAction(s, u)</tt> returns the state the robot would be in after performing action <tt>u</tt> in state <tt>s</tt>.  <tt>u</tt> must be one of strings <tt>'LEFT&rsquo;</tt>, <tt>'RIGHT&rsquo;</tt>, or 'FORWARD&rsquo;, and <tt>s</tt> must be a tuple of a position integer (0 through 8) and an angle integer in degrees, going clockwise from 0 as north.  This will return a new state in the same format as <tt>s</tt>.</p>
</div></div>
<div class="infoblock solutionblock">
<div class="blocktitle">Solution<span class="solutionhelp"> (hover to show)</span>:</div>
<div class="blockcontent">
<p>We are given that each initial state is equally likely, and we have \(9 \times 4=36\) possible states.  Thus,</p>
<p style="text-align:center">
\[
    P(X_0=x_0) = \frac{1}{36} \approx 0.0277
\]
</p><p>We also seek \(P(X_{t}=x_t|X_{t-1}=x_{t-1}, U_{t}=u_{t})\), or the probability of transitioning to a state \(x_t\) from state \(x_{t-1}\) given action \(u_t\).  This will be either \(1\) or \(0\), as our actions are deterministic (the same thing happens every time when action \(u\) is taken from state \(t\)).  In code, this can be implemented as <tt>int(x_t==gm.simulatedAction(x_tminusone, u))</tt>.</p>
<p>Finally, we can implement \(P(Y_t=y_t | X_t=x_t)\) as a gaussian with mean \(\mu_t\) set by where we are in the maze (\(x_t\)).  So, an implementation using only a forwards sensor reading could be \(\mathcal N(y_t, \mu=\mu_t, \sigma=5)\) with <tt>mu_t = gm.simulatedDistance(x_t[0], x_t[1])</tt> using the previous convention of state being a tuple of <tt>(position, angle)</tt>.</p>
</div></div>
<h3>Putting it together</h3>
<p>Implement a random walk on your robot in a loop by choosing randomly at each iteration whether to go forwards, turn left, or turn right.  Then, implement the forward algorithm and print the most likely robot state at each iteration!</p>
<p>Once you've implemented the system, try it out from a few starting places in the maze.  How many iterations does it take to converge to the right position?  Does your implementation always converge?  Discuss some strengths and limitations of this system with your group.</p>
<div class="infoblock">
<div class="blocktitle">Challenge problem</div>
<div class="blockcontent">
<p>If your initial solution only used one sensor reading per iteration, try upgrading to using sensor readings from multiple angles.  Can you make other improvements that allow your robot to localize quicker?</p>
</div></div>
</td>
</tr>
</table>
</body>
</html>
